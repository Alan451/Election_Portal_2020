{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <title>Gymkhana Elections 2021</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script type="text/javascript" src="http://code.jquery.com/jquery-1.7.1.min.js"></script>
    <script type="text/javascript" src="{% static 'js/camvas.js' %}"></script>
    <script type="text/javascript" src="{% static 'js/Ipoc.js' %}"></script>
    <script type="text/javascript" src="{% static 'js/pico.js' %}"></script>
    <link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">
    <style type="text/css">  
        /* Flipping the video as it was not mirror view */  
        video {  
            -webkit-transform: scaleX(-1);  
            transform: scaleX(-1);  
        }
      
        /* Flipping the canvas image as it was not mirror view */  
        #canvas {  
            filter: FlipH;  
            -ms-filter: "FlipH";
            transform: scale(0.75, 0.7);
        }
        
        @media (min-width: 640px) { 
            #canvas {
                transform: scale(0.75, 0.7);
            }
        }
        
        @media (min-width: 1500px) {
            /* #btnCapture {
                position: relative;
                left: 25px;
            } */

            /* .form-class {
                position: relative;
                left: 70px;
            } */

            #canvas {
                position: relative;
                right: 30px;
                transform: scale(0.8, 0.95);
            }
        }
        
        /* @media (min-width: 1600px) { */
            /* #btnCapture {
                position: relative;
                left: 50px; */
            /* } */

            /* .form-class {
                position: relative;
                left: 55px;
            } */
        /* } */

        @media (min-width: 1700px) {
            #canvas {
                transform: scale(1, 1);
            }
        }
    </style>
    <link rel="stylesheet" href="{% static 'css/verification.css' %}">
    
</head>
<body onload="geoFindMe();button_callback();">


    <div class="grid grid-rows-6 grid-cols-none lg:grid-rows-5 lg:grid-cols-10">
        <div id="video-resize" class="place-self-center lg:place-self-auto relative lg:left-8 top-12 lg:top-32 lg:col-start-2 lg:col-span-3 row-start-1 row-span-3">
            <p class="relative top-10 lg:top-0 px-12 lg:px-0 text-left text-3xl lg:text-2xl">Please allow camera and location access on your device :)</p>
            <br>
            <div class="relative lg:right-10">
                <canvas style="background-color:white;" id="canvas" width="640" height="480"></canvas>
            </div>
        </div>
        <div class="place-self-center lg:place-self-auto -mt-72 lg:mt-0 col-start-1 lg:col-start-6 lg:col-span-4 row-start-5 row-span-3 lg:row-start-2 lg:row-span-3">
            <p class="px-10 lg:px-0 text-5xl">{{request.user.first_name}}</p>
            <p class="px-10 lg:px-0 text-2xl">{{year}}  {{hostel}} hostel</p>
            <br>
            <p class="px-10 lg:px-0 text-xl lg:text-lg" id="status"></p>
            <p class="px-10 lg:px-0 text-xl lg:text-lg">IP address: {{request.session.ip}}</p>
            <p class="px-10 lg:px-0 text-xl lg:text-lg">Voter Token ID: {{voter_id}}</p>
            <br>
        </div>
        <div class="form-class pl-20 col-start-1 lg:col-start-6 row-start-6 row-span-3 lg:row-start-3 lg:row-span-3">
            <form action="" method="post"> 
                {% csrf_token %}
                <div class="lg:relative lg:top-24">
                    {{ form }}
                    <br>
                    <input class="
                    transition login_button relative text-black lg:top-5 bg-white border-2 border-black py-4 px-12 focus:outline-none hover:bg-blue-600 hover:text-white rounded text-lg z-60" id="continueBtn" type="submit" value="Continue" disabled>
                </div>
            </form>
        </div>
        <div class="lg:col-start-2 lg:col-span-3 place-self-center row-start-4 row-span-1 lg:row-span-3">
            <button id="btnCapture" type="button" class="focus:bg-blue-500 relative bottom-10 lg:bottom-28 left-7 rounded-full shadow-lg bg-gray-100 w-24 h-24 lg:w-16 lg:h-16 hover:bg-blue-500">
                <img class="w-14 h-12 lg:h-7 ml-4 lg:ml-1" id="camera" src="{% static 'icons/camera.svg' %}" alt="">
                <img class="w-14 h-12 lg:h-7 ml-4 lg:ml-1 hidden" id="video_camera" src="{% static 'icons/video.svg' %}" alt="">
            </button>
        </div>
    </div>
    <script>
        var initialized = false;
        var faceDetected = false;
        function button_callback() {
			/*
				(0) chseck whether we're already running face detection
			*/
			if(initialized)
				return; // if yes, then do not initialize everything again
			/*
				(1) initialize the pico.js face detector
			*/
			var update_memory = pico.instantiate_detection_memory(5); // we will use the detecions of the last 5 frames
			var facefinder_classify_region = function(r, c, s, pixels, ldim) {return -1.0;};
			var cascadeurl = "{% static 'js/facefinder' %}";
			fetch(cascadeurl).then(function(response) {
				response.arrayBuffer().then(function(buffer) {
					var bytes = new Int8Array(buffer);
					facefinder_classify_region = pico.unpack_cascade(bytes);
					console.log('* facefinder loaded');
				})
			})
			/*
				(2) initialize the lploc.js library with a pupil localizer
			*/
			var do_puploc = function(r, c, s, nperturbs, pixels, nrows, ncols, ldim) {return [-1.0, -1.0];};
			var puplocurl = "{% static 'js/puploc.bin' %}"
			fetch(puplocurl).then(function(response) {
				response.arrayBuffer().then(function(buffer) {
					var bytes = new Int8Array(buffer);
					do_puploc = lploc.unpack_localizer(bytes);
					console.log('* puploc loaded');
				})
			})
			/*
				(3) get the drawing context on the canvas and define a function to transform an RGBA image to grayscale
			*/
			var ctx = document.getElementById('canvas').getContext('2d');
			function rgba_to_grayscale(rgba, nrows, ncols) {
				var gray = new Uint8Array(nrows*ncols);
				for(var r=0; r<nrows; ++r)
					for(var c=0; c<ncols; ++c)
						// gray = 0.2*red + 0.7*green + 0.1*blue
						gray[r*ncols + c] = (2*rgba[r*4*ncols+4*c+0]+7*rgba[r*4*ncols+4*c+1]+1*rgba[r*4*ncols+4*c+2])/10;
				return gray;
			}
			/*
				(4) this function is called each time a video frame becomes available
			*/
			var processfn = function(video, dt) {
                // render the video frame to the canvas element and extract RGBA pixel data
                
                var c = document.getElementById('canvas');
                ctx.drawImage(video, 0, 0);
				var rgba = ctx.getImageData(0, 0,640,480).data;
				// prepare input to `run_cascade`
				image = {
					"pixels": rgba_to_grayscale(rgba, 480, 640),
					"nrows": 480,
					"ncols": 640,
					"ldim": 640
				}
				params = {
					"shiftfactor": 0.1, // move the detection window by 10% of its size
					"minsize": 100,     // minimum size of a face
					"maxsize": 1000,    // maximum size of a face
					"scalefactor": 1.1  // for multiscale processing: resize the detection window by 10% when moving to the higher scale
				}
				// run the cascade over the frame and cluster the obtained detections
				// dets is an array that contains (r, c, s, q) quadruplets
				// (representing row, column, scale and detection score)
				dets = pico.run_cascade(image, facefinder_classify_region, params);
				dets = update_memory(dets);
				dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
				// draw detections
				for(i=0; i<dets.length; ++i)
					// check the detection score
					// if it's above the threshold, draw it
					// (the constant 50.0 is empirical: other cascades might require a different one)
					if(dets[i][3]>50.0)
					{
						var r, c, s;
						faceDetected = true;
						// ctx.beginPath();
						ctx.strokeRect(dets[i][1]-0.45*dets[i][2], dets[i][0]-0.45*dets[i][2], dets[i][2],dets[i][2]);
						ctx.lineWidth = 0.5;
						ctx.strokeStyle = 'orange';
						ctx.stroke();
						//
						// find the eye pupils for each detected face
						// starting regions for localization are initialized based on the face bounding box
						// (parameters are set empirically)
						// first eye
						r = dets[i][0] - 0.075*dets[i][2];
						c = dets[i][1] - 0.175*dets[i][2];
						s = 0.35*dets[i][2];
						[r, c] = do_puploc(r, c, s, 63, image)
						if(r>=0 && c>=0)
						{
							// ctx.beginPath();
							// ctx.arc(c, r, 1, 0, 2*Math.PI, false);
							// ctx.lineWidth = 3;
							// ctx.strokeStyle = 'red';
							// ctx.stroke();
						}
						// second eye
						r = dets[i][0] - 0.075*dets[i][2];
						c = dets[i][1] + 0.175*dets[i][2];
						s = 0.35*dets[i][2];
						[r, c] = do_puploc(r, c, s, 63, image)
						if(r>=0 && c>=0)
						{
							// ctx.beginPath();
							// ctx.arc(c, r, 1, 0, 2*Math.PI, false);
							// ctx.lineWidth = 3;
							// ctx.strokeStyle = 'red';
							// ctx.stroke();
						}
					}
			}
			/*
				(5) instantiate camera handling (see https://github.com/cbrandolino/camvas)
			*/
			var mycamvas = new camvas(ctx, processfn);
			/*
				(6) it seems that everything went well
			*/
			initialized = true;
		}
	</script>
   <script type="text/javascript">  
      var pic = false;
        function sleep(ms) {
            return new Promise(resolve => setTimeout(resolve, ms));
        }
      // Below code to capture image from Video tag (Webcam streaming)  
      $("#btnCapture").click(async function () {  
          console.log("clicked");
          var canvas = document.getElementById('canvas');  
          var context = canvas.getContext('2d');  
    
          // Capture the image into canvas from Webcam streaming Video element  
          context.drawImage(video, 0, 0);  
          if(pic){
            $('#video').get(0).play();
            // document.getElementById("btnCapture").innerHTML = "Click";
            $("#camera").toggleClass("hidden");
            $("#video_camera").toggleClass("hidden");
            console.log("camera clicked!");
            pic=false;
          }
          else{
            faceDetected=false;
            await sleep(200);//if the last face detected is before 200 ms dont allow to click
            if (faceDetected==false){
              alert('No face in video')
            }  
            else{
                
                $('#video').get(0).pause();
                // document.getElementById("btnCapture").innerHTML = "Reclick";
                $("#camera").toggleClass("hidden");
                $("#video_camera").toggleClass("hidden");
                // document.getElementById("camera").src = "{% static 'icons/camera.svg' %}";
                pic = true;
            }
          }
          sendImage();
      }); 
     
     var image = false
     var geol = false
      // Upload image to server - ajax call - with the help of base64 data as a parameter  
     
     function sendImage() {  
          image = false ;
        
          // Below new canvas to generate flip/mirron image from existing canvas  
          var destinationCanvas = document.createElement("canvas");  
          var destCtx = destinationCanvas.getContext('2d');  
    
    
          destinationCanvas.height = 500;  
          destinationCanvas.width = 500;  
    
          destCtx.translate(video.videoWidth, 0);  
          destCtx.scale(-1, 1);  
          destCtx.drawImage(document.getElementById("canvas"), 0, 0);  
    
          // Get base64 data to send to server for upload  
          var imagebase64data = destinationCanvas.toDataURL("image/png");
          var allCookies = document.cookie;
          var csrf = allCookies.substring(10);
          imagebase64data = imagebase64data.replace('data:image/png;base64,', '');  
          var postdata = {
            imagebase64data: imagebase64data,
            'csrfmiddlewaretoken': csrf
          };
          var url = "{% url 'image' %}";
          $.post(url, postdata)
          .done(function(){
            image = true;
            if (image && geol){
                document.getElementById("continueBtn").disabled = false;
            }
          });
        // return true;
      };
  </script>   

<!-- location verification javascript -->

<script>
    function post_req(data){
        geol = false;
        var allCookies = document.cookie;
        var csrf = allCookies.substring(10);
        var postdata = {
            data: JSON.stringify(data),
            'csrfmiddlewaretoken': csrf
        };
        var url = "{% url 'geo' %}";
        $.post(url, postdata)
        .done(function(){
            geol = true;
            if (image && geol){
                document.getElementById("continueBtn").disabled = false;
            }
        });
    }   
    function geoFindMe() {
        const status = document.querySelector('#status');
        
        function success(position) {
        const latitude  = position.coords.latitude;
        const longitude = position.coords.longitude;
        data = {
                        lat: latitude,
                        long: longitude,
                        }
        
        post_req(data);              
        status.textContent = 'GeoLocation : (lat : ' +latitude+', long : ' + longitude + ')';
        
        }

        function error() {
        status.textContent = 'Unable to retrieve your location';
            
        }

        if(!navigator.geolocation) {
        status.textContent = 'Geolocation is not supported by your browser';
        } else {
            status.textContent = 'GeoLocation : Locating ... ';
        navigator.geolocation.getCurrentPosition(success, error);
        }

    }

    // document.querySelector('#find-me').addEventListener('click', geoFindMe);
    
</script>

</body>
</html>